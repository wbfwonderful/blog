[{"title":"Hello World 👋","url":"/blog/hello-world/","content":"😏欢迎来到我的博客你也许可以看到：\n\n✍️学习记录\n💻技术分享\n📑日常流水账\n…\n\n"},{"title":"【Kaggle Courses】3-机器学习介绍","url":"/blog/Kaggle-course/intro-to-ML/","content":"Learn the core ideas in machine learning, and build your first models. Click here for more information.\n\n\n模型是如何工作的？\nThe first step.\n\n引入考虑以下场景：\n\n你表弟做房地产投机赚了几百万美元。因为你对数据科学感兴趣，他提出要和你成为商业伙伴。他会提供钱，你会提供模型来预测各种房子的价值。\n你问你的堂兄他过去是如何预测房地产价值的，他说这只是直觉。但更多的质疑表明，他从过去看过的房子中识别出了价格模式，并用这些模式来预测他正在考虑的新房。\n…\n\n考虑这个简单的决策树：它只把房子分成两类。所考虑的任何房屋的预测价格都是同一类别房屋的历史平均价格。\n通过数据来决定如何将房屋分为两类，同时决定其预测价格。从数据中捕获模式的这一步称为拟合(fitting)或训练(training)模型。用于拟合模型的数据称为训练数据(training data)。\n改进决策树以下哪个决策树更有效？左边的决策树（决策树1）可能更有意义，因为它抓住了一个现实，即卧室多的房子往往比卧室少的房子卖得更高。这种模式最大的缺点是，它没有考虑到影响房价的大多数因素，比如浴室数量、地块大小、位置等。\n可以使用具有更多“分裂”的树来捕获更多因素。这些树被称为“更深的”树。考虑到每栋房子地块总面积的决策树可能是这样的：房子的预测价格在这棵树的底部。我们做出预测的底部点被称为叶子 (leaf)。\n初步探索数据\nLoad and understand your data.\n\n使用 Pandas 来加载数据Pandas 是数据科学家用来探索和操作数据的主要工具。大多数人在代码中将 pandas 缩写为 pd：\nimport pandas as pd\nPandas 库中最重要的部分是 DataFrame。DataFrame 保存了您可能认为是表的数据类型。这类似于 Excel 中的工作表或 SQL 数据库中的表。\n使用如下命令来读取 csv 文件，并进行展示：\ndf = pd.read_csv(&#x27;my_csv.csv&#x27;)df.describe()\n更多关于 pandas 的介绍。\n对数据的解释某个 csv 文件通过 .describe() 展示的结果为：\n\n结果为原始数据集中的每列显示8个数字。第一个数字是 count，显示有多少行具有非缺失值。\n缺失值的产生有很多原因。例如，在调查一间卧室的房子时，不会收集第二间卧室的大小。我们将回到丢失数据的话题。\n\n\n第二个值是均值，也就是平均值。在此之下，std 是标准偏差，它衡量数值的数值分布。\n后续五个值：将该列的数据升序排序形成一个列表，在列表中走四分之一，会发现一个大于 25% 且小于 75% 的值。这是 25% 的定义。\n\n第一个机器学习模型\nBuilding your first model. Hurray!\n\n选择建模的数据一条数据有很多变量，如何选择合适的变量？我们先用直觉选几个变量。后面的课程将展示自动确定变量优先级的统计技术。\n首先需要查看数据集中所有列的列表。通过 DataFrame 的 columns 属性完成：\nimport pandas as pdmelbourne_file_path = &#x27;../input/melbourne-housing-snapshot/melb_data.csv&#x27;melbourne_data = pd.read_csv(melbourne_file_path) print(melbourne_data.columns)\nIndex([&#x27;Suburb&#x27;, &#x27;Address&#x27;, &#x27;Rooms&#x27;, &#x27;Type&#x27;, &#x27;Price&#x27;, &#x27;Method&#x27;, &#x27;SellerG&#x27;,       &#x27;Date&#x27;, &#x27;Distance&#x27;, &#x27;Postcode&#x27;, &#x27;Bedroom2&#x27;, &#x27;Bathroom&#x27;, &#x27;Car&#x27;,       &#x27;Landsize&#x27;, &#x27;BuildingArea&#x27;, &#x27;YearBuilt&#x27;, &#x27;CouncilArea&#x27;, &#x27;Lattitude&#x27;,       &#x27;Longtitude&#x27;, &#x27;Regionname&#x27;, &#x27;Propertycount&#x27;],      dtype=&#x27;object&#x27;)\n某些数据可能有缺失值，后续课程会解决缺失值。这里简单地删除有缺失的数据，通过 .dropna()：\nmelbourne_data = melbourne_data.dropna(axis=0)\n注意 .dropna() 不会在当前 DataFrame 上进行修改，而是会返回一个新的对象，所以需要赋值给新对象。\n获取 DataFrame 子集的方法：\n\n使用点 .\n使用一个列名列表\n\n选择预测目标通过点 . 来访问某个变量的数据。这些数据存储在一个 Series 中，它大致类似于只有单列数据的 DataFrame 。需要预测的变量为 Price ，定义为y：\ny = melbourne_data.Price\n\n选择特征“特征”定义为输入模型的数据列，并后续用于预测。使用列名列表来获取，并定义为 x：\nmelbourne_features = [&#x27;Rooms&#x27;, &#x27;Bathroom&#x27;, &#x27;Landsize&#x27;, &#x27;Lattitude&#x27; &#x27;Longtitude&#x27;]x = melbourne_data[melbourne_features]\n使用 .head() 方法查看头部几个样本：\nx.head()\n\n构建模型使用 scikit-learn 包来创建模型。代码中写作 sklearn。\n通过以下步骤来构建模型：\n\n定义：模型类型、模型参数\n拟合（训练）：从数据中学习模式\n预测：Just what it sounds like（原文🤔）\n评估：确定模型的准确度\n\n一个简单的例子：\nfrom sklearn.tree import DecisionTreeRegressor# Define model. Specify a number for random_state to ensure same results each runmelbourne_model = DecisionTreeRegressor(random_state=1)# Fit modelmelbourne_model.fit(X, y)\n\n设置 random_state 确保在每一个轮次中获取相同的结果。但是模型的性能和这个数字无关。\n现在使用训练好的模型来预测输入的前 5 个数据：\nmelbourne_model.predict(X.head())\n模型验证\nMeasure the performance of your model, so you can test and compare alternatives.\n\n什么是模型验证许多人在衡量预测准确性时犯了一个巨大的错误。他们用训练数据进行预测，并将这些预测与训练数据中的目标值进行比较。稍后您将看到这种方法的问题以及如何解决它，但让我们先考虑一下如何做这个。\n考虑最简单的平均绝对误差（Mean Absolute Error, MAE）：\nerror = actual - predicted\n\n使用 scikit-learn 计算 MAE：\nfrom sklearn.metrics import mean_absolute_errorpredicted_home_prices = melbourne_model.predict(X)mean_absolute_error(y, predicted_home_prices)\n\n“In-Sample”分数的问题前面提到的评价方式是一种“样本内”分数（in-sample）。是同统一数据来训练和预测。想象以下场景：\n\n在大型房地产市场中，门的颜色与房价无关。然而，在您用于构建模型的数据样本中，所有带有绿色门的房屋都非常昂贵。这个模型的工作是找到预测房价的模式，所以它会看到这个模式，它总是会预测绿色门的房屋的高价格。由于该模式是从训练数据中导出的，因此该模型在训练数据中会显得准确。但是，如果当模型看到新的数据时，这种模式不成立，那么在实际使用时，模型将非常不准确。\n\n由于模型的实用价值来自于对新数据的预测，因此我们在未用于构建模型的数据上衡量性能。要做到这一点，最直接的方法是从模型构建过程中排除一些数据，然后使用这些数据来测试模型对以前没有见过的数据的准确性。这些数据称为验证数据（validation data）。\nCoding it!scikit-learn 提供了 train_test_solit 方法来划分训练集和测试集。\nfrom sklearn.model_selection import train_test_split# split data into training and validation data, for both features and target# The split is based on a random number generator. Supplying a numeric value to# the random_state argument guarantees we get the same split every time we# run this script.train_X, val_X, train_y, val_y = train_test_split(X, y, random_state = 0, test_size=0.2)# Define modelmelbourne_model = DecisionTreeRegressor()# Fit modelmelbourne_model.fit(train_X, train_y)# get predicted prices on validation dataval_predictions = melbourne_model.predict(val_X)print(mean_absolute_error(val_y, val_predictions))\n\n通过设置 test_size 来更改测试集的比例。\nWow!经过测试，样本内数据的平均绝对误差约为500美元，而样本外超过25万美元！\n欠拟合和过拟合\nFine-tune your model for better performance.\n\n实验不同模型两个极端\n\n当我们把房子分成许多片叶子时，每片叶子上的房子也更少。房子很少的树叶会做出非常接近这些房子的实际价值的预测，但它们对新数据的预测可能非常不可靠（因为每次预测都只基于几所房子）。\n这是一种被称为过拟合的现象，即模型几乎完美地匹配训练数据，但在验证和其他新数据方面表现不佳。另一方面，如果我们把树画得很浅，它就不会把房子分成很明显的组。\n\n\n如果一棵树只把房子分成2个或4个，每一组仍然有各种各样的房子。对大多数机构来说，结果预测可能还很遥远，甚至在训练数据中也是如此（出于同样的原因，它在验证中也会很糟糕）。\n当一个模型无法捕捉数据中的重要区别和模式，因此即使在训练数据中也表现不佳，这被称为欠拟合。\n\n\n\n例子通过设置不同数量的决策树结点数量 max_leaf_nodes，计算出不同的精确率。\nfrom sklearn.metrics import mean_absolute_errorfrom sklearn.tree import DecisionTreeRegressordef get_mae(max_leaf_nodes, train_X, val_X, train_y, val_y):    model = DecisionTreeRegressor(max_leaf_nodes=max_leaf_nodes, random_state=0)    model.fit(train_X, train_y)    preds_val = model.predict(val_X)    mae = mean_absolute_error(val_y, preds_val)    return(mae)\n\n结论两种情况：\n\n过拟合：捕捉未来不会再出现的虚假模式，导致预测不那么准确\n欠拟合：无法捕捉相关的模式，同样导致预测不准确\n\n随机森林\nUsing a more sophisticated machine learning algorithm.\n\n引入决策树留给你一个艰难的决定。有很多叶子的深树会过拟合，因为每个预测都是来自叶子附近的少数房屋的历史数据。但是一棵叶子很少的浅树会表现得很差，因为它无法在原始数据中捕捉到尽可能多的区别。\n即使是今天最复杂的建模技术也面临着欠拟合和过拟合之间的紧张关系。但是，许多模型都有聪明的想法，可以带来更好的性能。我们将以随机森林为例。\n随机森林使用许多树，它通过平均每个组成树的预测来进行预测。它通常比单一决策树具有更好的预测准确性，并且在默认参数下工作得很好。\nfrom sklearn.ensemble import RandomForestRegressorfrom sklearn.metrics import mean_absolute_errorforest_model = RandomForestRegressor(random_state=1)forest_model.fit(train_X, train_y)melb_preds = forest_model.predict(val_X)print(mean_absolute_error(val_y, melb_preds))\n结论可能还有进一步改进的空间，但这已经比25万的最佳决策树误差有了很大的改进。有一些参数允许你改变随机森林的性能，就像我们改变单个决策树的最大深度一样。但随机森林模型的一个最佳特征是，即使没有这种调整，它们通常也能合理地工作。\n机器学习比赛\nEnter the world of machine learning competitions to keep improving and see your progress.\n\nIt’s your turn!\n","categories":["Kaggle courses"],"tags":["Kaggle","Pandas","Python"]},{"title":"【Kaggle Courses】1-编程介绍","url":"/blog/Kaggle-course/intro-to-programming/","content":"Get started with Python, if you have no coding experience. Click here for more information.\n\n\n计算和变量\nMake calculations, and define and modify variables.\n\n打印打印一条消息。\nprint(&#x27;hello&#x27;)\n计算打印计算结果。\nprint(1 + 2)\n注释使用 # 写注释。\n函数\nOrganize your code and avoid redundancy.\n\n一个简单的例子def add_three(input_var):    output_var = input_var + 3    return output_var\n函数包含两个部分: header 和 body.\n\nHeader: 定义函数名和参数。\nBody: 定义函数如何工作。\n\n变量作用域函数内部定义的变量无法在函数外访问。\n数据类型\nExplore integers, floats, booleans, and strings.\n\nint, float, boolean, string\n条件和条件声明\nModify how functions run, depending on the input.if, if-else, if-elif-else\n\n列表介绍\nOrganize your data so you can work with it efficiently.\n\n索引\n获取最后一个元素: [-1]\n获取倒数第二个元素: [-2]\n\n切片切片：获取列表的一个片段。\n\n获取前 x 个元素：[:x]\n获取后 y 个元素：[-y:]\n\n此处“元素”的英文为“entry”。\nl = [1, 2, 3, 4, 5]print(l[:2])print(l[-2:])\n[1, 2][4, 5]\n删除使用 .remove()\n添加使用 .add()\n","categories":["Kaggle courses"],"tags":["Kaggle","Python"]},{"title":"【Kaggle Courses】4-pandas","url":"/blog/Kaggle-course/pandas-kaggle/","content":"Solve short hands-on challenges to perfect your data manipulation skills. Click here for more information.\n\n创建、读和写\nYou can’t work with data if you can’t read it. Get started here.\n\n开始导入 pandas：\nimport pandas as pd\n创建数据Pandas 中的两个核心对象：DataFrame 和 Series。\nDataFrameDataFrame 是一个表。它包含一个单独条目（entry）的数组，每个条目都有一个特定的值。每个条目对应一行（或记录）和一列。例如：\npd.DataFrame(&#123;&#x27;Yes&#x27;: [50, 21], &#x27;No&#x27;: [131, 2]&#125;)\n在本例中，“0，No” 条目的值为 131 。“0，Yes” 条目的值为 50，以此类推。数据框条目不限于整数。例如，下面是一个值为字符串的DataFrame：\npd.DataFrame(&#123;&#x27;Bob&#x27;: [&#x27;I liked it.&#x27;, &#x27;It was awful.&#x27;], &#x27;Sue&#x27;: [&#x27;Pretty good.&#x27;, &#x27;Bland.&#x27;]&#125;)\n\n我们使用 pd.DataFrame() 构造函数来生成这些 DataFrame 对象。声明一个新对象的语法是一个字典，它的键是列名（本例中是Bob和Sue），它的值是一个条目列表。这是构造新 DataFrame 的标准方法。\n字典列表构造函数将值赋给列标签，但对行标签来说，默认是从 0 开始的升序计数。\nDataFrame 中使用的行标签列表称为索引。可以通过在构造函数中使用 index 形参给它赋值：\npd.DataFrame(&#123;&#x27;Bob&#x27;: [&#x27;I liked it.&#x27;, &#x27;It was awful.&#x27;],               &#x27;Sue&#x27;: [&#x27;Pretty good.&#x27;, &#x27;Bland.&#x27;]&#125;,             index=[&#x27;Product A&#x27;, &#x27;Product B&#x27;])\n\nSeries相比之下，序列是数据值的序列。如果 DataFrame 是一个表，那么 Series 就是一个列表。只需要一个列表就可以创建一个 Series 对象：\npd.Series([1, 2, 3, 4, 5])\n\n从本质上讲，Series 是 DataFrame 的一列。因此，可以像以前一样使用 index 参数将行标签分配给 Series。但是， Series 没有列名，它只有一个总称：\npd.Series([30, 35, 40], index=[&#x27;2015 Sales&#x27;, &#x27;2016 Sales&#x27;, &#x27;2017 Sales&#x27;], name=&#x27;Product A&#x27;)\n\n读取数据数据可以以许多不同的形式和格式中的任何一种进行存储。到目前为止，其中最基本的是 CSV 文件。当你打开一个 CSV 文件时，你会看到这样的东西：\nProduct A,Product B,Product C,30,21,9,35,34,1,41,11,11\nCSV 文件本质上是一个用逗号分隔的值表。因此得名：Comma-Separated Values，CSV。\n读取并查看 CSV 文件：\nimport pandas as pddf = pd.read_csv(&#x27;file.csv&#x27;)df.shapedf.head()\n\n索引、选择和赋值\nPro data scientists do this dozens of times a day. You can, too!\n\n原生访问器原生 Python 对象提供了索引数据的方法。Pandas包含了所有这些内容：\ndf = pd.read_csv(&#x27;file.csv&#x27;)# 访问 country 列（访问一个 Series ）df.countrydf[&#x27;country&#x27;]# 访问该列的某个对象df[&#x27;country&#x27;][0]\nPandas 中的索引Pandas 有自己的索引方式 loc 。Pandas 索引的工作方式有两种。\n基于索引的选择iloc 基于数值位置选择数据。例如访问第一行的数据：\ndf.iloc[0]\n\nloc 和 iloc 都是行优先，这意味着检索行稍微容易一些，而获取检索列稍微困难一些。例如访问第一列的数据：\ndf.iloc[:, 0]\n\n更多例子：\n# 访问第二行和第三行的第一列df.iloc[1 : 3, 0]# 也可以是一个列表df.iloc[[1, 2], 0]\n\n基于标签的选择iloc 在概念上比 loc 简单，因为它忽略数据集的索引。当使用 iloc 时，我们将数据集视为一个大矩阵（列表的列表），我们必须根据位置对其进行索引。\n相比之下，loc 使用索引中的信息来完成工作。由于数据集通常包含有意义的索引，因此使用loc通常更容易。例如，访问所有行的以下属性：\ndf.loc[:, [&#x27;taster_name&#x27;, &#x27;taster_twitter_handle&#x27;, &#x27;points&#x27;]]\n\nloc 还是 iloc ？\niloc 使用标准的索引策略，0:10 的结果是 0,...,9，而 loc 的结果是 0,...,10。\nloc 可以这样用：df.loc[&#39;a&#39;:&#39;d&#39;] ，表示索引标签 a 到 d 之间的所有列。（包括 d）\niloc 索引数值位置，loc 索引标签，且 loc 包括“结尾”。\n\n操作索引Pandas 默认使用数字作为索引，可以通过 set_index() 将指定列设置为索引：\ndf = df.set_index(&quot;title&quot;)\n\n注意，重新设置索引之后要进行赋值。即不会在原来的基础上进行修改，而是会返回一个新的 DataFrame 对象。\n条件选择例如，假设我们对意大利生产的好于平均水平的葡萄酒特别感兴趣。\n我们首先需要检查每一瓶酒是否来自意大利：\ndf.country == &#x27;Italy&#x27;\n\n这个操作会返回一个全是布尔变量的 Series 对象。表示该行的 country 属性是否为 Italy 。\n接下来可以通过 loc 来选择对应的行：\ndf.loc[df.country == &#x27;Italy&#x27;]\n可以使用 &amp; 或者 | 来携带多个条件：\ndf.loc[(df.country == &#x27;Italy&#x27;) &amp; (reviews.points &gt;= 90)]\n\n此外，pandas 还提供了一些内置的选择器：isin() 和 isnull()\nisin() 选择那些值在给定列表里的数据。例如选取包含意大利和法国的行：\ndf.loc[df.country.isin([&#x27;Italy&#x27;, &#x27;France&#x27;])]# 等价于df.loc[(df.country == &#x27;Italy&#x27;) | (df.country == &#x27;France&#x27;)]\n\nisnull() 选择那些包含空值的行：\ndf.loc[df.price.isnull()]\n赋值给一整列赋值：\n# 将整列都赋值为 everyonereviews[&#x27;critic&#x27;] = &#x27;everyone&#x27;# 也可以使用可迭代的对象（list、range等）reviews[&#x27;index_backwards&#x27;] = range(len(reviews), 0, -1)\n\n总结函数和映射\nExtract insights from your data.\n\n总结函数使用 describe() 方法获取对数据的高级描述：\n对不同的数据类型，会有不同的总结，例如对字符串：\nmean() 方法：查看某一列的平均值。\nunique() 方法：查看某一列的唯一值列表。（对应于 describe 输出的 unique 关键字）\ncount() 方法：查看某一列的唯一值列表以及其出现次数。\n映射（Maps）批量修改某些列。\n例如，想要将某一列减去其均值：\nreview_points_mean = reviews.points.mean()reviews.points.map(lambda p: p - review_points_mean)\n传递给 map() 的函数应该期望得到来自 Series 的单个值（在上面的示例中是一个点值，即 p），并返回该值的转换版本（即 p - review_points_mean）。map（）返回一个新的 Series ，其中所有的值都已被函数转换过。\n这里 lambda 表示匿名函数，其等价于以下函数：\ndef my_function(p):    return p - review_points_mean\n\n同样地， apply() 方法同样可以实现上述过程：\ndef remean_points(row):    row.points = row.points - review_points_mean    return rowreviews.apply(remean_points, axis=&#x27;columns&#x27;)\n\n此外，也可以直接使用操作符 + 、 - 等直接对 Series 对象进行操作，这比上述两个函数更高效，但是不支持更复杂的情况。\n分组和排序\nScale up your level of insight. The more complex the dataset, the more this matters\n\n分组分析以下代码等同于 value_counts() 方法：\nreviews.groupby(&#x27;points&#x27;).points.count()\n\n即按照 points 列进行分组，分组之后再对 point 列进行计数。\nreviews.groupby(&#x27;points&#x27;).price.min()\n上述代码按照 points 列进行分组，分组之后，在每个组里面计算最小值。\n生成的每个组可以视为 DataFrame 的一个片段，其中仅包含具有匹配值的数据。可以直接使用 apply() 方法访问这个 DataFrame，然后可以通过任何方式操作数据。例如，下面是从数据集中的每个酒厂中选择第一个被评论的葡萄酒名称的一种方法：\nreviews.groupby(&#x27;winery&#x27;).apply(lambda df: df.title.iloc[0])\n\n对于更细粒度的，还可以按多个列分组。举个例子，以下是我们如何按国家和省份挑选最好的葡萄酒：\nreviews.groupby([&#x27;country&#x27;, &#x27;province&#x27;]).apply(lambda df: df.loc[df.points.idxmax()])\n\n排序简单排序（默认升序）：\ncountries_reviewed.sort_values(by=&#x27;len&#x27;)\n\n按照多个列进行排序：\ncountries_reviewed.sort_values(by=[&#x27;country&#x27;, &#x27;len&#x27;])\n\n数据类型和缺失值\nDeal with the most common progress-blocking problems\n\n数据类型DataFrame 或Series 中每列的数据类型称为 dtype 。可以使用 dtype 属性获取特定列的类型。\nreviews.price.dtype\n\ndtypes 属性返回 DataFrame 中每一列的数据类型。\nreviews.dtypes\n\n注意，字符串的类型为 object 。\n可以使用 astype() 方法进行数据转换：\nreviews.points.astype(&#x27;float64&#x27;)\n\n缺失值使用 fillna() 方法来替换缺失值。通常可以设置为“unkonwn”字符串，便于后续更改。这种值通常被称作“哨兵”，还包括“Undisclosed”、“Invalid”等。\n此外可以使用 replace() 方法来替换设置的哨兵值。\n重命名和组合\nData comes in from many sources. Help it all make sense together\n\n重命名有时需要更改列明或索引名。\n# 将 points 列更名为 scorereviews.rename(columns=&#123;&#x27;points&#x27;: &#x27;score&#x27;&#125;)# 将第一行和第二行更名为 firstEntry 和 secondEntryreviews.rename(index=&#123;0: &#x27;firstEntry&#x27;, 1: &#x27;secondEntry&#x27;&#125;)\n\n组合组合来自多个 DataFrame 或 Series 的数据。\n例如，两个 CSV 文件有相同的列，最简单的方法是 conca() 。\ncanadian_youtube = pd.read_csv(&quot;../input/youtube-new/CAvideos.csv&quot;)british_youtube = pd.read_csv(&quot;../input/youtube-new/GBvideos.csv&quot;)pd.concat([canadian_youtube, british_youtube])\n\n例如，组合两个具有相同索引的 CSV 文件：\nleft = canadian_youtube.set_index([&#x27;title&#x27;, &#x27;trending_date&#x27;])right = british_youtube.set_index([&#x27;title&#x27;, &#x27;trending_date&#x27;])left.join(right, lsuffix=&#x27;_CAN&#x27;, rsuffix=&#x27;_UK&#x27;)\nlsuffix 和 rsuffix 参数用于区分两个相同的列。\n简单读写 CSV 文件读import pandas as pddf = pd.read_csv(&#x27;./file.csv&#x27;)\n写for i, row in df.iterrows():    path = row[&#x27;path&#x27;]    label = row[&#x27;label&#x27;]\n新建data = &#123;    &#x27;path&#x27;: [&#x27;path1&#x27;, &#x27;path2&#x27;],    &#x27;label&#x27;: [&#x27;label1&#x27;, &#x27;label2&#x27;]&#125;    new_df = pd.DateFrame(data)new_df.to_csv(&#x27;./new_file.csv&#x27;, index=False)\nloc 方法定位某一行path = df.loc[index][&#x27;path&#x27;]\n\n定位某列的指定值df = df.loc[df[&#x27;label&#x27;] == &#x27;Normal&#x27;]df = df.reset_index()","categories":["Kaggle courses"],"tags":["Kaggle","Pandas","Python"]},{"title":"【Kaggle Courses】2-python","url":"/blog/Kaggle-course/python-kaggle/","content":"coming soon…\n","tags":["Kaggle","Python"]},{"title":"【LLM】nanoGPT学习","url":"/blog/LLM/nanogpt/","content":"写在前面本文主要记录 nanoGPT 的学习过程，参考链接\n\nGPT in 60 Lines of NumPy：https://jaykmody.com/blog/gpt-from-scratch/60 行代码实现 gpt（上一篇的翻译）： https://zhuanlan.zhihu.com/p/679330102nanoGPT 实战： https://zhuanlan.zhihu.com/p/716442447nanoGPT 代码解读：https://zhuanlan.zhihu.com/p/677407971\n\nGPT 原理\nGPT(Generative Pre-trained Transformer)基于Transformer解码器自回归地预测下一个Token，从而进行了语言模型的建模。GPT的伪代码可以简单的表示为：\n\ndef gpt(inputs: list[int]) -&gt; list[list[float]]:\t&quot;&quot;&quot; GPT代码，实现预测下一个token\tinputs：List[int], shape为[n_seq]，输入文本序列的token id的列表\toutput：List[List[int]], shape为[n_seq, n_vocab]，预测输出的logits列表\t&quot;&quot;&quot;    output = # 需要实现的GPT内部计算逻辑     return output\n\n即输入一段token\n\n关于 token\ntoken 可以理解为一个句子中最小的组成部分。通常为一个词，一些情况下，可以进行简化，例如后续使用莎士比亚的作品集进行训练时，将字符作为 token。\n\ntoken 通过分词器来获取，对应一个词汇表。最开始输入到模型中的序列其实为一串数字，表示当前 token 在词汇表中的位置。例如：\n# 词汇表中的token索引表示该token的整数ID# 例如，&quot;robot&quot;的整数ID为1，因为vocab[1] = &quot;robot&quot;vocab = [&quot;must&quot;, &quot;robot&quot;, &quot;obey&quot;, &quot;the&quot;, &quot;orders&quot;, &quot;.&quot;]# 进行分词的分词器tokenizer（假设通过空格来进行分词）tokenizer = WhitespaceTokenizer(vocab)# encode()方法将str字符串转换为list[int]ids = tokenizer.encode(&quot;robot must obey orders&quot;) # ids = [1, 0, 2, 4]# 通过词汇表映射，可以看到实际的token是什么tokens = [tokenizer.vocab[i] for i in ids] # tokens = [&quot;robot&quot;, &quot;must&quot;, &quot;obey&quot;, &quot;orders&quot;]# decode()方法将list[int] 转换回strtext = tokenizer.decode(ids) # text = &quot;robot must obey orders&quot;\n\n同样，输出为一个二维数组，表示当前位置不同 token 的出现概率。output 是一个二维数组，其中 output[i][j] 表示文本序列的第 i 个位置的 token（inputs[i]）是词汇表的第 j 个 token（vocab[j]）的概率（实际为未归一化的logits得分）。例如：\ninputs = [1, 0, 2, 4]  # &quot;robot&quot; &quot;must&quot; &quot;obey&quot; &quot;orders&quot;vocab = [&quot;must&quot;, &quot;robot&quot;, &quot;obey&quot;, &quot;the&quot;, &quot;orders&quot;, &quot;.&quot;]output = gpt(inputs)# output[0] = [0.75, 0.1, 0.15, 0.0, 0.0, 0.0]# 给定 &quot;robot&quot;，模型预测 &quot;must&quot; 的概率最高# output[1] = [0.0, 0.0, 0.8, 0.1, 0.0, 0.1]# 给定序列 [&quot;robot&quot;, &quot;must&quot;]，模型预测 &quot;obey&quot; 的概率最高# output[-1] = [0.0, 0.0, 0.1, 0.0, 0.85, 0.05]# 给定整个序列[&quot;robot&quot;, &quot;must&quot;, &quot;obey&quot;]，模型预测 &quot;orders&quot; 的概率最高next_token_id = np.argmax(output[-1])  # next_token_id = 4next_token = vocab[next_token_id]      # next_token = &quot;orders&quot;\n在推理时（生成文本），首先将 prompt 输入 GPT，然后迭代地将上一轮的输出放到当前的末尾，重复生成。例如：\ndef generate(inputs, n_tokens_to_generate):\t&quot;&quot;&quot; GPT生成代码\tinputs: list[int], 输入文本的token ids列表\tn_tokens_to_generate：int, 需要生成的token数量\t&quot;&quot;&quot;    # 自回归式解码循环    for _ in range(n_tokens_to_generate):         output = gpt(inputs)            # 模型前向推理，输出预测词表大小的logits列表        next_id = np.argmax(output[-1]) # 贪心采样        inputs.append(int(next_id))     # 将预测添加回输入    return inputs[len(inputs) - n_tokens_to_generate :]  # 只返回生成的ids# 随便举例input_ids = [1, 0, 2]                          # [&quot;robot&quot;, &quot;must&quot;, &quot;obey&quot;]output_ids = generate(input_ids, 1)            #  output_ids = [1, 0, 2, 4]output_tokens = [vocab[i] for i in output_ids] # [&quot;robot&quot;, &quot;must&quot;, &quot;obey&quot;, &quot;orders&quot;]\n\n代码首先，最外层调用的是 GPT 类。调用方法为：\nlogits, loss = model(X, Y)\n其中 X，Y 表示输入以及其对应的标签，注意这里已经为 int 类型的数组了（表示 token 在词汇表中的位置）。\nGPT 类整体结构def forward(self, idx, targets=None):    device = idx.device    b, t = idx.size()    assert t &lt;= self.config.block_size, f&quot;Cannot forward sequence of length &#123;t&#125;, block size is only &#123;self.config.block_size&#125;&quot;    pos = torch.arange(0, t, dtype=torch.long, device=device)    tok_emb = self.transformer.wte(idx)     pos_emb = self.transformer.wpe(pos)     x = self.transformer.drop(tok_emb + pos_emb)    for block in self.transformer.h:        x = block(x)    x = self.transformer.ln_f(x)    if targets is not None:        logits = self.lm_head(x)        loss = F.cross_entropy(logits.view(-1, logits.size(-1)), targets.view(-1), ignore_index=-1)    else:        logits = self.lm_head(x[:, [-1], :]) # note: using list [-1] to preserve the time dim        loss = None    return logits, loss\n\n输入 idx 类型为 list[int]，表示输入 token 在词汇表中的索引，并且有 batch 维度。此处有一个断言，即要求序列的长度要小于块长度，即 block_size 表示模型能处理的最大长度。\n新建一个位置数组 pso，用于计算位置编码。\n接下来为核心代码 self.transformer，实现如下self.transformer = nn.ModuleDict(dict(    wte = nn.Embedding(config.vocab_size, config.n_embd),    wpe = nn.Embedding(config.block_size, config.n_embd),    drop = nn.Dropout(config.dropout),    h = nn.ModuleList([Block(config) for _ in range(config.n_layer)]),    ln_f = LayerNorm(config.n_embd, bias=config.bias),))\n其包含 5 个部分：token 编码（word token embedding, wte）、位置编码（word position embedding, wpe）、dropout、注意力块（block）和层归一化。\n整体处理流程为：\ntoken 编码 + 位置编码，并相加\n依次通过注意力层\n经过最终的映射层（将注意力的输出映射到词汇表维度）\n最后进行判断是否计算 loss\n\n\n\ntoken 编码和位置编码\ntoken 编码：wte 是一个 [n_vocab, n_embd] 大小的可学习参数矩阵，它充当一个 token 嵌入查找表，其中矩阵的第 i 对应于词汇表中第 i 个 token 的 embedding。\nwte[idx] 使用 Token Ids 列表索引来检索与输入中每个token对应的向量。\n\n\n位置编码：表示序列的先后信息，同样是一个 [n_block, n_embd] 大小的可学习参数矩阵。\n\nBlock 类\nBlock 类的实现如下：class Block(nn.Module):    def __init__(self, config):        super().__init__()        self.ln_1 = LayerNorm(config.n_embd, bias=config.bias)        self.attn = CausalSelfAttention(config)        self.ln_2 = LayerNorm(config.n_embd, bias=config.bias)        self.mlp = MLP(config)    def forward(self, x):        x = x + self.attn(self.ln_1(x))        x = x + self.mlp(self.ln_2(x))        return x\n其主要包含两个层归一化、MLP和注意力层。\n\nCausalSelfAttention 类实现注意力机制的核心类。\ndef forward(self, x):    B, T, C = x.size() # batch size, sequence length, embedding dimensionality (n_embd)    # calculate query, key, values for all heads in batch and move head forward to be the batch dim    q, k, v  = self.c_attn(x).split(self.n_embd, dim=2)    k = k.view(B, T, self.n_head, C // self.n_head).transpose(1, 2) # (B, nh, T, hs)    q = q.view(B, T, self.n_head, C // self.n_head).transpose(1, 2) # (B, nh, T, hs)    v = v.view(B, T, self.n_head, C // self.n_head).transpose(1, 2) # (B, nh, T, hs)    # causal self-attention; Self-attend: (B, nh, T, hs) x (B, nh, hs, T) -&gt; (B, nh, T, T)    if self.flash:        # efficient attention using Flash Attention CUDA kernels        y = torch.nn.functional.scaled_dot_product_attention(q, k, v, attn_mask=None, dropout_p=self.dropout if self.training else 0, is_causal=True)    else:        # manual implementation of attention        att = (q @ k.transpose(-2, -1)) * (1.0 / math.sqrt(k.size(-1)))        att = att.masked_fill(self.bias[:,:,:T,:T] == 0, float(&#x27;-inf&#x27;))        att = F.softmax(att, dim=-1)        att = self.attn_dropout(att)        y = att @ v # (B, nh, T, T) x (B, nh, T, hs) -&gt; (B, nh, T, hs)    y = y.transpose(1, 2).contiguous().view(B, T, C) # re-assemble all head outputs side by side    # output projection    y = self.resid_dropout(self.c_proj(y))    return y\n\nself.c_attn(x) 表示为注意力机制的映射层，并将 Q、K、V 三个映射层合并为一个，减少计算量。计算出映射矩阵后再进行划分。\nself.c_attn = nn.Linear(config.n_embd, 3 * config.n_embd, bias=config.bias)\n\n接下来根据 head 的数量对映射矩阵进行划分。然后就是计算注意力。\n\n注意，为了实现因果机制，即模型只能看到当前 token 之前的 token，需要将计算出的 attn 矩阵 mask 一部分。\n# 输入是 [&quot;not&quot;, &quot;all&quot;, &quot;heroes&quot;, &quot;wear&quot;, &quot;capes&quot;] # 原始自注意力        not    all   heroes  wear  capes   not 0.116  0.159  0.055  0.226  0.443   all 0.180  0.397  0.142  0.106  0.175heroes 0.156  0.453  0.028  0.129  0.234  wear 0.499  0.055  0.133  0.017  0.295 capes 0.089  0.290  0.240  0.228  0.153 # 因果自注意力 （行为j, 列为i） # 为防止输入的所有查询都能预测未来，需要将所有j&gt;i位置设置为0 ：        not    all   heroes  wear  capes   not 0.116  0.     0.     0.     0.   all 0.180  0.397  0.     0.     0.heroes 0.156  0.453  0.028  0.     0.  wear 0.499  0.055  0.133  0.017  0. capes 0.089  0.290  0.240  0.228  0.153 # 在应用 softmax 之前，我们需要修改我们的注意力矩阵，得到掩码自注意力 # 即，在softmax之前将要屏蔽项的注意力得分设置为 −∞（归一化系数为0） # mask掩码矩阵 0 -1e10 -1e10 -1e10 -1e10 0   0   -1e10 -1e10 -1e10 0   0     0   -1e10 -1e10 0   0     0     0   -1e10 0   0     0     0     0 使用 -1e10 而不是 -np.inf ，因为 -np.inf 可能会导致 nans\n\n至此，整个 GPT 的结构拆解完毕。\n","categories":["LLM"],"tags":["LLM"]},{"title":"【代码随想录】数组1-二分查找","url":"/blog/Leetcode/array1/","content":"基本知识\n数组元素按照顺序排列\n数组元素无法删除，只能替代（填充）\npython 中，使用 list，代码中 List 是类型注解中的一种表示方式，通常出现在类型提示中。python 3.9 之后可以使用内置的 list 来替代 List。\n\n704. 二分查找\n题目链接 link\n\n给定一个 n 个元素有序的（升序）整型数组 nums 和一个目标值 target  ，写一个函数搜索 nums 中的 target，如果目标值存在返回下标，否则返回 -1。\n\n输入: nums &#x3D; [-1,0,3,5,9,12], target &#x3D; 9输出: 4解释: 9 出现在 nums 中并且下标为 4     \n\n两个要点\n数组中元素按照顺序排列\n无重复的数字（否则元素下标不唯一）\n如果有重复的数字，要求返回最小的那个呢？\n\n\n\n解法\n区间定义：定义 target 所在的区间是左闭右开还是左右全闭\n核心：将数组分割为三个部分\n左右全闭：[0, middle-1] , middle, [middle + 1, len - 1] 或者\n左开右闭：[0, middle) , middle, [middle + 1, len)\n\n\n\n左右全闭\n区间为 [left, right]：\n定义 right 为 len(nums) - 1，因为 right 要有含义\n循环条件 while(left &lt;&#x3D; right) ，因为left &#x3D;&#x3D; right是有意义的\n判断条件，若 middle 大于 target ，则遍历左区间，设置 right &#x3D; middle - 1，因为此时为右闭区间，不会再访问 middle；同理，若 middle 小于 target，则遍历右边区间，设置 left &#x3D; middle + 1，同样因为是闭区间，不会再访问 middle。\n\n\n代码：class Solution:    def search(self, nums: List[int], target: int) -&gt; int:        left = 0        right = len(nums) - 1        while left &lt;= right:            middle = int((left + right) / 2)            if nums[middle] &gt; target:                right = middle - 1            elif nums[middle] &lt; target:                left = middle + 1            else:                return middle        return -1        \n\n左闭右开\n区间为 [left, right)：\n\n定义 right 为 len(nums)，因为不会访问 right，所以设置为区间长度\n循环条件 while(left &lt; right) ，因为left &#x3D;&#x3D; right没有意义（右边为开区间）\n判断条件，若 middle 大于 target ，则遍历左区间，设置 right &#x3D; middle，因为此时为右开区间，设置 right&#x3D;middle 实际上下一次会访问 middle - 1 。\n\n\n代码：\nclass Solution:    def search(self, nums: List[int], target: int) -&gt; int:        left = 0        right = len(nums)        while left &lt; right:            middle = int((left + right) / 2)            if nums[middle] &gt; target:                right = middle            elif nums[middle] &lt; target:                left = middle + 1            else:                return middle        return -1 \n\n相关题目1：35. 搜索插入位置\n题目链接 link\n\n给定一个排序数组和一个目标值，在数组中找到目标值，并返回其索引。如果目标值不存在于数组中，返回它将会被按顺序插入的位置。\n你可以假设数组中无重复元素。\n要点\n无重复元素 + 升序排列，考虑二分查找\n\n这道题相较于二分查找，只是多了一个 target 不存在的情况，在这个情况下，一定满足 left &#x3D;&#x3D; right + 1 （左右都为闭区间的情况）\n\n因为，在循环的最后一轮，满足 left &#x3D;&#x3D; right，此时 只剩下最后一个数字，middle 也为 left （right）。此时若 middle 数小于 target，则 left + 1，反之则 right - 1。\n基于这个原理，若 middle 数小于 target，target 应该放在 middle + 1 上，若 middle 数大于 target，则 target 应该放在 middle 上\n对比上述两条，可以发现：\nmiddle 数小于 target，left + 1，放在 middle + 1的位置\nmiddle 数大于 target， right - 1, middle 不变，放在 middle 的位置\nmiddle 的变化和 left 相同，即小于时加1，大于时不变，而最后一轮循环时 middle、left、right 均相同，则最后的结果一定为 left。\n\n\n\n\n代码如下，只需将二分查找的代码的最后一行，改为 return left 即可\nclass Solution:    def search(self, nums: List[int], target: int) -&gt; int:        left = 0        right = len(nums) - 1        while left &lt;= right:            middle = int((left + right) / 2)            if nums[middle] &gt; target:                right = middle - 1            elif nums[middle] &lt; target:                left = middle + 1            else:                return middle        return left\n\n相关题目2：34. 在排序数组中查找元素的第一个和最后一个位置\n题目链接 link给定一个按照升序排列的整数数组 nums，和一个目标值 target。找出给定目标值在数组中的开始位置和结束位置。\n\n如果数组中不存在目标值 target，返回 [-1, -1]。\n进阶：你可以设计并实现时间复杂度为 $O(\\log n)$ 的算法解决此问题吗？\n示例 1：\n\n输入：nums &#x3D; [5,7,7,8,8,10], target &#x3D; 8输出：[3,4]\n\n示例 2：\n\n输入：nums &#x3D; [5,7,7,8,8,10], target &#x3D; 6输出：[-1,-1]\n\n示例 3：\n\n输入：nums &#x3D; [], target &#x3D; 0输出：[-1,-1]\n\n思路\n相似于二分查找，分别找左边界和右边界，找到一个目标后\n若要找左边界，则在找到的目标的左边数组中再次查找，right &#x3D; middle - 1。即认为当前找到的数比实际的 target 大。\n相似的，若要找右边界，则在找到的目标的右边数组中再次查找，left &#x3D; middle + 1。即认为当前找到的数比实际的 target 小。class Solution:    def searchRange(self, nums: List[int], target: int) -&gt; int:                leftb = mySearch(nums, target, True)        rightb = mySearch(nums, target, False)        def mySearch(nums: List[int], target: int, side: bool):            left = 0            right = len(nums) - 1            res = -1            while left &lt;= right:                middle = int((left + right) / 2)                if nums[middle] &gt; target:                    right = middle - 1                elif nums[middle] &lt; target:                    left = middle + 1                else:                    res = middle                    if side:                        # 左边界                        right = middle - 1                    else:                        left = middle + 1            return res        return [leftb, rightb]\n\n\n\n相关题目3：367. 有效的完全平方数\n题目链接 link给你一个非负整数 x ，计算并返回 x 的 算术平方根 。\n\n由于返回类型是整数，结果只保留 整数部分 ，小数部分将被 舍去 。\n注意：不允许使用任何内置指数函数和算符，例如 pow(x, 0.5) 或者 x ** 0.5 。\n示例 1：\n\n输入：x &#x3D; 4输出：2\n\n示例 2：\n\n输入：x &#x3D; 8输出：2解释：8 的算术平方根是 2.82842…, 由于返回类型是整数，小数部分将被舍去。\n\n思路\n二分查找，找到第一个平方不大于 x 的数字。class Solution:    def mySqrt(self, x: int) -&gt; int:        left = 0        right = x - 1        if x == 0: return 0        if x == 1: return 1        while left &lt;= right:            middle = int((left + right) / 2)            if middle * middle &gt; x:                right = middle - 1            elif middle * middle &lt; x:                left = middle + 1            else:                return middle        return right        \n\n","categories":["Leetcode"],"tags":["Array"]},{"title":"【ML2025】1-生成式人工智能","url":"/blog/ML2025/gen-AI/","content":"\n李宏毅老师《机器学习》2025学习记录\n\n\n生成式人工智能有什么样的行为？\n现有的模型通常会体现“思考”的过程（脑内小剧场？？）。\n未来 AI 的工作不再局限于“一问一答”，很多任务需要多个步骤来完成 –&gt; AI agent\n使用 AI agent 来训练模型？？\n\n运作机制\n生成式人工智能的基本原理：输入一段 token，输出另一段 token。任何事物都可以由多个 token 表示：\nThose tokens were words, some of the tokens of course could now be images, or charts, or tables, songs … speech, videos. Those tokens could be anything. token 可以是单词，图片、表、歌曲、对话等等……\n\n\n\n\n\n不论什么任务，本质上都是 token 到 token。\n\n具体来说，是给输入 token 序列，预测下一个 token。\n然后将预测的 token 与输入的 token 序列拼接，然后再次输入到模型中，预测下一个 token，重复上述步骤，直到结束。\n\n\n例如，输入图像，输出文字，那么 z 就代表所有文字 token 和图像 token 的集合\n\n通常是使用深度网络来预测下一个 token。一个不恰当的比喻，假设任务为三个数字相加，每一个层为一个查表操作，如果只用一个层，那么需要存10^3种可能，如果分为两层，那么只需要10*10+19*10种可能。\n\n本质上，让模型“思考”（reason）也是一种“深度”。\n\n困难的问题需要思考很多步，layer 的深度不够了？\n深度不够，长度来凑！\n\n\n\n内容是怎样产生出来的？\n我们要怎样得到可以生成内容的模型？三步走！\nFind Function with Unknown Parameters\nDefine Loss from Training Data\nOptimation\n\n\n生成式模型也不是新的问题：从“专才”到“通才”的转变\n如何实现这个转变？大概包含以下三个阶段\n阶段一：训练通用的编码器，只能将输入 token 转换为 embedding，要实现下游任务，需要接对应的解码器。  \n阶段二：没那么好用的模型，只能生成 token，需要在特定任务上微调（相同架构，不同的参数）  \n阶段三：大模型时代！一个模型可以解决所有的问题（相同架构，相同参数）  \n\n\n\n如何赋予模型新的能力？\n方法1：微调\n\n方法2：模型编辑\n\n方法3：模型合并\n\n\n","categories":["ML2025"],"tags":["ML"]},{"title":"Pycharm debug 方法记录","url":"/blog/Mark/debug/","content":"Pycharm 调试按钮\n参考链接\n\n\nstep over（F8快捷键）：在单步执行时，在函数内遇到子函数时不会进入子函数内单步执行，而是将子函数整个执行完再停止，也就是把子函数整个作为一步。在不存在子函数的情况下是和step into效果一样的。\nstep into（F7快捷键）：在单步执行时，遇到子函数就进入并且继续单步执行，有的会跳到源代码里面去执行。\nstep into my code（Alt+Shift+F7快捷键）：在单步执行时，遇到子函数就进入并且继续单步执行，不会进入到源码中。\nstep out（Shift+F8快捷键）：假如进入了一个函数体中，看了两行代码，不想看了，跳出当前函数体内，返回到调用此函数的地方。\nResume program (F9快捷键)：恢复程序，直接运行到下一断点处。若无下一断点，则直接跑完程序。\n\n调试时带参数\n参考链接\n\n\nrun -&gt; edit configurations\n新建选择 python，name 随便写，script 选择要 debug 的文件，下方填要添加的参数，最下方选择 “debug” 点击即可\n\n\n\n\n","categories":["狠狠mark住"],"tags":["Python","Pytorch"]},{"title":"git timeout 报错443解决方法","url":"/blog/Mark/git-443/","content":"\n参考链接\n\n解决方法\n查看代理的端口号（clash 的 General 菜单中，默认为7890）\n查看并取消 git 的 http 和 https 代理// 首先，查一下当前全局的 http 代理：git config --global http.proxy// 如果有代理，就取消git config --global --unset http.proxy // 再查 https 的代理：git config --global https.proxy// 同样的，有就取消git config --global --unset https.proxy\n设置代理//设置git端口号和上面的端口号保持一致git config --global http.proxy http://127.0.0.1:7890git config --global https.proxy https://127.0.0.1:7890\n\n","categories":["狠狠mark住"],"tags":["Git"]},{"title":"hexo基本命令","url":"/blog/Mark/hexo-command/","content":"快速开始创建新博客$ hexo new &quot;My New Post&quot;\n\n\n运行服务器$ hexo server\n动态部署，修改代码实时更新。\n生成静态文件$ hexo generate\n\n远端部署$ hexo deploy\n\n\n清理缓存$ hexo clean\nDon’t forget to clean cache…\n标签插件链接到其他博客页面使用 post_link 标签。注意要以 &#x2F;_posts 文件夹为根路径。即使两个 post 在同一个子文件下，也需要写出子文件夹的名字，例如下面的 hello-world 页面位于 _post 文件夹下，就直接写文件名。\n&#123;% post_link 相对路径 &#x27;链接文字&#x27; %&#125;&lt;!-- &#123;% post_link hello-world &#x27;访问首页&#x27; %&#125; --&gt;\n访问首页\n\n引用块&#123;% blockquote [author[, source]] [link] [source_link_title] %&#125;content&#123;% endblockquote %&#125;\nexample\nhexo-official代码块\n\n代码块&#123;% codeblock %&#125;alert(&#x27;Hello World!&#x27;);&#123;% endcodeblock %&#125;\n等同于使用反引号 \n``` your code ``` \n\n\nHexo新建文章到子目录hexo new 命令说明：\nUsage: hexo new [layout] &lt;title&gt;Description:Create a new post.Arguments:  layout  Post layout. Use post, page, draft or whatever you want.  title   Post title. Wrap it with quotations to escape.Options:  -p, --path     Post path. Customize the path of the post.  -r, --replace  Replace the current post if existed.  -s, --slug     Post slug. Customize the URL of the post.\n例如，在 202411/ 文件夹下新建 test.md 文件\nhexo n -p 202411/test.md\n\n","categories":["狠狠mark住"],"tags":["Hexo"]},{"title":"Huggingface 相关问题","url":"/blog/Mark/hf/","content":"更换 Huggingface 源\nexport HF_ENDPOINT&#x3D;https://hf-mirror.com\n\n一键下载 Huggingface 模型下载 huggingface-cli 。\n\nhuggingface-cli download model_name –local-dir .&#x2F;your_download_dir\n\n只需要更改 model_name 和 ./your_download_dir 。\n","categories":["狠狠mark住"],"tags":["LLM"]},{"title":"Numpy 报错：numpy is not available","url":"/blog/Mark/numpy/","content":"描述报错如下：\n\nA module is compiled with numpy 1.X cannot be run in numpy 2.X\n\n解决方法换旧版本的 numpy\npip uninstall numpypip install numpy==1.25.3\n","categories":["狠狠mark住"],"tags":["Python","Pytorch"]},{"title":"Ubuntu 内核与 Nvidia 驱动不匹配问题","url":"/blog/Mark/nvidia-kernal/","content":"\n一定要关系自动更新！！\n卸载并安装驱动\nhttps://www.cnblogs.com/aliving/articles/18389099\n\n\n更改内核版本\nhttps://blog.csdn.net/damifeng/article/details/132985518\n\n查看可以安装的内核版本（机子上曾经下过的，不会删除）\n\ndpkg –get-selections|grep linux\n\n\n下载指定版本\n  sudo apt-get install linux-image-xxx-genericsudo apt-get install linux-headers-xxx-genericsudo apt-get install linux-modules-xxx-genericsudo apt-get install linux-modules-extra-xxx-genericsudo apt-get install linux-tools-xxx-generic\n更新 initramfs\n\nsudo update-initramfs -u -k all\n\n\n修改 grub，选择指定内核\n\nhttps://www.8kiz.cn/archives/14385.html\n开机狂按 shift，选择 advanced options\n\n\n一定要\n  sudo update-grub\n\n\n删除下载的内核（不是真的删除）\nhttps://download.csdn.net/blog/column/12270246/130411204\n\n\n\n","categories":["狠狠mark住"],"tags":["Linux"]},{"title":"【代码随想录】数组2-双指针法","url":"/blog/Leetcode/array2/","content":"27. 移除元素\n题目链接 link\n\n给你一个数组 nums 和一个值 val，你需要 原地 移除所有数值等于 val 的元素，并返回移除后数组的新长度。\n不要使用额外的数组空间，你必须仅使用 O(1) 额外空间并原地修改输入数组。\n元素的顺序可以改变。你不需要考虑数组中超出新长度后面的元素。\n示例 1: \n\n给定 nums &#x3D; [3,2,2,3], val &#x3D; 3, 函数应该返回新的长度 2, 并且 nums 中的前两个元素均为 2。 你不需要考虑数组中超出新长度后面的元素。\n\n示例 2: \n\n给定 nums &#x3D; [0,1,2,2,3,0,4,2], val &#x3D; 2, 函数应该返回新的长度 5, 并且 nums 中的前五个元素为 0, 1, 3, 0, 4。\n\n你不需要考虑数组中超出新长度后面的元素。\n注意：需要改动原来的数组，虽然没有直接返回改动后的数组\n暴力解法两个循环，分别用于查找 val 和移动后续元素。注意第一个循环要用 while，因为移动后续元素时减少了一位，for 循环无法控制变量 i。\nclass Solution:    def removeElement(self, nums: List[int], val: int) -&gt; int:        size = len(nums)        i = 0        while i &lt; size:            if nums[i] == val:                for j in range(i+1, size):                    nums[j-1] = nums[j]                size -= 1                i -= 1            i += 1        return size\n\n双指针法双指针法（快慢指针法）： 通过一个快指针和慢指针在一个for循环下完成两个for循环的工作。本题中，两个指针分别代表：\n\n快指针：查找的索引\n慢指针：更改后的数组的索引此外，每一步都需要把快指针的值赋值给慢指针（无论是否遇到等于）class Solution:    def removeElement(self, nums: List[int], val: int) -&gt; int:        size = len(nums)        fast, slow = 0, 0        while fast &lt; size:            nums[slow] = nums[fast]            if nums[fast] == val:                slow -= 1            fast += 1            slow += 1                return slow\n\n26. 删除有序数组中的重复项\n题目链接 link\n\n给你一个 非严格递增排列 的数组 nums ，请你 原地 删除重复出现的元素，使每个元素 只出现一次 ，返回删除后数组的新长度。元素的 相对顺序 应该保持 一致 。然后返回 nums 中唯一元素的个数。\n考虑 nums 的唯一元素的数量为 k ，你需要做以下事情确保你的题解可以被通过：\n更改数组 nums ，使 nums 的前 k 个元素包含唯一元素，并按照它们最初在 nums 中出现的顺序排列。nums 的其余元素与 nums 的大小不重要。返回 k 。\n示例 1：\n\n输入：nums &#x3D; [1,1,2]输出：2, nums &#x3D; [1,2,_]解释：函数应该返回新的长度 2 ，并且原数组 nums 的前两个元素被修改为 1, 2 。不需要考虑数组中超出新长度后面的元素。\n\n示例 2：\n\n输入：nums &#x3D; [0,0,1,1,1,2,2,3,3,4]输出：5, nums &#x3D; [0,1,2,3,4]解释：函数应该返回新的长度 5 ， 并且原数组 nums 的前五个元素被修改为 0, 1, 2, 3, 4 。不需要考虑数组中超出新长度后面的元素。\n\n思路仍然是快慢指针法，只是没有给定 val，需要在循环中动态更新 val。更新 val 的规则为，如果当前 fast 对应的值不等于 val，则将其赋值给 val。因为数组升序排列，相同的数字在一起，如果 fast 对应的值和 val（上一个数字）不相等，说明上一个数字已经不重复了。\nclass Solution:    def removeDuplicates(self, nums: List[int]) -&gt; int:        slow, fast = 0, 0        size = len(nums)        val = None               while fast &lt; size:            nums[slow] = nums[fast]            if val == nums[fast]:                slow -= 1            else:                val = nums[fast]            slow += 1            fast += 1        return slow\n283. 移动零\n题目链接 link\n\n给定一个数组 nums，编写一个函数将所有 0 移动到数组的末尾，同时保持非零元素的相对顺序。\n请注意 ，必须在不复制数组的情况下原地对数组进行操作。\n示例 1:\n\n输入: nums &#x3D; [0,1,0,3,12]输出: [1,3,12,0,0]\n\n示例 2:\n\n输入: nums &#x3D; [0]输出: [0]\n\n思路相当于是 val 为 0 的删除元素，同样使用快慢指针法，只是最后需要将 [slow, fast) 区间内的元素赋值为 0。\nclass Solution:    def moveZeroes(self, nums: List[int]) -&gt; None:        &quot;&quot;&quot;        Do not return anything, modify nums in-place instead.        &quot;&quot;&quot;        slow, fast, size = 0, 0, len(nums)        while fast &lt; size:            nums[slow] = nums[fast]            if nums[fast] == 0:                slow -= 1            slow += 1            fast += 1                if fast != slow:            for i in range(slow, fast):                nums[i] = 0\n844. 比较含退格的字符串\n题目链接 link\n\n给定 s 和 t 两个字符串，当它们分别被输入到空白的文本编辑器后，如果两者相等，返回 true 。# 代表退格字符。\n注意：如果对空文本输入退格字符，文本继续为空。\n示例 1：\n\n输入：s &#x3D; “ab#c”, t &#x3D; “ad#c”输出：true解释：s 和 t 都会变成 “ac”。\n\n示例 2：\n\n输入：s &#x3D; “ab##”, t &#x3D; “c#d#”输出：true解释：s 和 t 都会变成 “”。\n\n示例 3：\n\n输入：s &#x3D; “a#c”, t &#x3D; “b”输出：false解释：s 会变成 “c”，但 t 仍然是 “b”。\n\n思路1双指针法，相当于是查找 “#” 字符，查找到之后删除 # 以及其之前的字符。注意要考虑 # 之前没有字符的情况。\nclass Solution:    def backspaceCompare(self, s: str, t: str) -&gt; bool:        def dele(nums: list):            slow, fast, size = 0, 0, len(nums)            while fast &lt; size:                nums[slow] = nums[fast]                if nums[fast] == &quot;#&quot;:                    if slow == 0:                        slow -= 1                    else:                        slow -= 2                                slow += 1                fast += 1            if slow &lt; 0:                return []            else:                return nums[0: slow]                s1 = dele(list(s))        t1 = dele(list(t))        s = &quot;&quot;.join(s1)        t = &quot;&quot;.join(t1)        if s == t:            return True        else:            return False\n\n思路2使用栈的思想，遍历到 # 字符，则当前栈顶的字符 pop。注意 list 的 pop 方法需要 list 不为空，所以需要进行判断。\nclass Solution:    def backspaceCompare(self, s: str, t: str) -&gt; bool:        def dele(nums: list):            ret = list()            for i in nums:                                if i != &quot;#&quot;:                                        ret.append(i)                elif len(ret) != 0:                    ret.pop()                        return &quot;&quot;.join(ret)        s = dele(list(s))        t = dele(list(t))                if s == t:            return True        else:            return False\n\n977. 有序数组的平方\n题目链接 link给你一个按 非递减顺序 排序的整数数组 nums，返回 每个数字的平方 组成的新数组，要求也按 非递减顺序 排序。\n\n示例 1：\n\n输入：nums &#x3D; [-4,-1,0,3,10]输出：[0,1,9,16,100]解释：平方后，数组变为 [16,1,0,9,100]排序后，数组变为 [0,1,9,16,100]\n\n示例 2：\n\n输入：nums &#x3D; [-7,-3,2,3,11]输出：[4,9,9,49,121]\n\n思路双指针法，左右分别两个指针，依次比较大小，直到左指针大于右指针。注意，这里需要返回新的数组，和上面的题目不一样，所以可以新建数组，不需要在原有数组上操作。\nclass Solution:    def sortedSquares(self, nums: List[int]) -&gt; List[int]:        left, right = 0, len(nums) - 1        new_nums = [0] * len(nums)        i = len(nums) - 1        while left &lt;= right:            if nums[left] * nums[left] &lt; nums[right] * nums[right]:                new_nums[i] = nums[right] * nums[right]                right -= 1            else:                new_nums[i] = nums[left] * nums[left]                left += 1            i -= 1        return new_nums        \n","categories":["Leetcode"],"tags":["Array"]}]